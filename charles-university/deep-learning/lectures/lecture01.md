# Feb 26

[Slides](https://ufal.mff.cuni.cz/~straka/courses/npfl114/1718/slides/?01),
[Recording](https://slideslive.com/38906857/deep-learning-lecture-1-introduction-to-deep-learning)

- Random variables, probability distributions, expectation, variance, Bernoulli
  distribution, Categorical distribution [Sections 3.2, 3.3, 3.8, 3.9.1 and 3.9.2 of DLB]
- Self-information, entropy, cross-entropy, KL-divergence [Section 3.13 of DBL]
- Gaussian distribution [Section 3.9.3 of DLB]
- *Machine Learning Basics [Section 5.1-5.1.3 of DLB]*
- *History of Deep Learning [Section 1.2 of DLB]*
- *Linear regression [Section 5.1.4 of DLB]*
- *Brief description of Logistic Regression, Maximum Entropy models and SVM [Sections 5.7.1 and 5.7.2 of DLB]*
- *Challenges Motivating Deep Learning [Section 5.11 of DLB]*
- Neural network basics (this topic is treated in detail withing the [lecture NAIL002](https://is.cuni.cz/studium/eng/predmety/index.php?do=predmet&kod=NAIL002))
  - Neural networks as graphs [Chapter 6 before Section 6.1 of DLB]
  - Output activation functions [Section 6.2.2 of DLB, excluding Section 6.2.2.4]
  - Hidden activation functions [Section 6.3 of DLB, excluding Section 6.3.3]
  - Basic network architectures [Section 6.4 of DLB, excluding Section 6.4.2]
