# Mar 12

[Slides](https://ufal.mff.cuni.cz/~straka/courses/npfl114/1718/slides/?03),
[Recording](https://slideslive.com/38906435/deep-learning-lecture-3-training-neural-networks-ii)

- *Training neural network with a single hidden layer*
- *Playing with TensorFlow Playground*
- Softmax with NLL (negative log likelihood) as a loss function [Section 6.2.2.3 of DLB, notably equation (6.30); plus slides 10-12]
- Regularization [Chapter 7 until Section 7.1 of DLB]
- Early stopping [Section 7.8 of DLB, without the *How early stopping acts as a regularizer* part]
- L2 and L1 regularization [Sections 7.1 and 5.6.1 of DLB; plus slides 17-18]
- Dataset Augmentation [Section 7.4 of DLB]
- Ensembling [Section 7.11 of DLB]
- Dropout [Section 7.12 of DLB]
