# Apr 16

[Slides](https://ufal.mff.cuni.cz/~straka/courses/npfl114/1718/slides/?08),
[Recording](https://slideslive.com/38907189/deep-learning-lecture-8-recurrent-neural-networks-ii-word-embeddings)

- Long Shoft-Term Memory (LSTM) [Section 10.10.1 of DLB, *[Sepp Hochreiter, Jürgen Schmidhuber (1997): Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf), [felix A. Gers, Jürgen Schmidhuber, Fred Cummins (2000): Learning to Forget: Continual Prediction with LSTM](ftp://ftp.idsia.ch/pub/juergen/FgGates-NC.pdf)*]
- Gated Recurrent Unit (GRU) [Section 10.10.2 of DLB, *[Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio: Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)*]
- `Word2vec` word embeddings, notably the CBOW and Skip-gram architectures [[Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean: Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)]
- Hierarchical softmax and Negative sampling [[Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean: Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)]
- Bidirectional RNN [Section 10.3 of DLB]
- Character-level embeddings using Recurrent neural networks [C2W model from [Wang Ling, Tiago Luís, Luís Marujo, Ramón Fernandez Astudillo, Silvio Amir, Chris Dyer, Alan W. Black, Isabel Trancoso: Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](http://arxiv.org/abs/1508.02096)]
- Character-level embeddings using Convolutional neural networks [CharCNN from [Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush: Character-Aware Neural Language Models](https://arxiv.org/abs/1508.06615)]
- Character-level embeddings using character n-grams [Described simultaneously in several papers as Charagram ([John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu: Charagram: Embedding Words and Sentences via Character n-grams](https://arxiv.org/abs/1607.02789)), Subword Information ([Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov: Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606) or SubGram ([Tom Kocmi, Ondřej Bojar: SubGram: Extending Skip-Gram Word Representation with Substrings](http://link.springer.com/chapter/10.1007/978-3-319-45510-5_21))]
