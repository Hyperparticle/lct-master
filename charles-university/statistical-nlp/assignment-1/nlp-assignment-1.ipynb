{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #1: PFL067 Statistical NLP\n",
    "\n",
    "## Exploring Entropy and Language Modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Entropy of a Text\n",
    "\n",
    "In this experiment, you will determine the conditional entropy of the word distribution in a text given the previous word. To do this, you will first have to compute P(i,j), which is the probability that at any position in the text you will find the word i followed immediately by the word j, and P(j|i), which is the probability that if word i occurs in the text then word j will follow. Given these probabilities, the conditional entropy of the word distribution in a text given the previous word can then be computed as:\n",
    "\n",
    "$$H(J|I) = -\\sum_{i \\in I, j \\in J} P(i,j) \\log_2 P(j|i)$$\n",
    "\n",
    "The perplexity is then computed simply as\n",
    "\n",
    "$$P_X(P(J|I)) = 2^{H(J|I)}$$\n",
    "\n",
    "Compute this conditional entropy and perplexity for `TEXTEN1.txt`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('TEXTEN1.txt')\n",
    "with open('TEXTEN1.txt') as f:\n",
    "    content = f.readlines()\n",
    "content = np.array([x.strip() for x in content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WHEN', 'on', 'board', 'H', '.', 'M', '.', 'S', '.', 'Beagle']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(J, I, P, Pcond):\n",
    "    return - np.sum(P(i, j) * np.log2(Pcond(j, i)) for j in J for i in I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0843587129994474"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P(i, j):\n",
    "    return 0.3\n",
    "\n",
    "H([0.5, 0.2], [0.5, 0.1], P, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. Where are probabilities calculated? From the specified text?\n",
    "2. What are J,I? Lists of words? Is I just J shifted over 1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
