{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Assignment #2: NPFL067 Statistical NLP II](http://ufal.mff.cuni.cz/~hajic/courses/npfl067/assign2.html)\n",
    "\n",
    "## Words and The Company They Keep\n",
    "\n",
    "### Author: Dan Kondratyuk\n",
    "\n",
    "### March 2, 2018\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook examines \n",
    "\n",
    "Code and explanation of results is fully viewable within this webpage.\n",
    "\n",
    "## Files\n",
    "\n",
    "- [index.html](./index.html) - Contains all veiwable code and a summary of results\n",
    "- [README.md](./README.md) - Instructions on how to run the code with Python\n",
    "- [nlp-assignment-2.ipynb](./nlp-assignment-1.ipynb) - Jupyter notebook where code can be run\n",
    "- [requirements.txt](./requirements.txt) - Required python packages for running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Best Friends\n",
    "\n",
    "#### Problem Statement\n",
    ">  In this task you will do a simple exercise to find out the best word association pairs using the pointwise mutual information method.\n",
    "\n",
    "> First, you will have to prepare the data: take the same texts as in the previous assignment, i.e.\n",
    "\n",
    "> `TEXTEN1.txt` and `TEXTCZ1.txt`\n",
    "\n",
    "> (For this part of Assignment 2, there is no need to split the data in any way.)\n",
    "\n",
    "> Compute the pointwise mutual information for all the possible word pairs appearing consecutively in the data, **disregarding pairs in which one or both words appear less than 10 times in the corpus**, and sort the results from the best to the worst (did you get any negative values? Why?) Tabulate the results, and show the best 20 pairs for both data sets.\n",
    "\n",
    "> Do the same now but for distant words, i.e. words which are at least 1 word apart, but not farther than 50 words (both directions). Again, tabulate the results, and show the best 20 pairs for both data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections as c\n",
    "from tqdm import tqdm\n",
    "from scipy.special import comb\n",
    "\n",
    "# Configure Plots\n",
    "plt.rcParams['lines.linewidth'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(200) # Set a seed so that this notebook has the same output each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_text(filename):\n",
    "    \"\"\"Reads a text line by line, applies light preprocessing, and returns an array of words\"\"\"\n",
    "    with open(filename, encoding='iso-8859-2') as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    preprocess = lambda word: word.strip()\n",
    "    \n",
    "    return np.array([preprocess(word) for word in content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the texts into memory\n",
    "english = './TEXTEN1.txt'\n",
    "czech = './TEXTCZ1.txt'\n",
    "\n",
    "words_en = open_text(english)\n",
    "words_cz = open_text(czech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    \"\"\"Counts words and calculates the probabilities of a language model\"\"\"\n",
    "    \n",
    "    def __init__(self, words, min_words=10):\n",
    "        self.min_words = min_words\n",
    "        \n",
    "        # Unigrams\n",
    "        self.unigrams = words\n",
    "        self.unigram_set = list(set(self.unigrams))\n",
    "        self.total_unigram_count = len(self.unigrams)\n",
    "        self.unigram_dist = c.Counter(self.unigrams)\n",
    "        \n",
    "        # Bigrams\n",
    "        self.bigrams = list(nltk.bigrams(words))\n",
    "        self.bigram_set = list(set(self.bigrams))\n",
    "        self.total_bigram_count = len(self.bigrams)\n",
    "        self.bigram_dist = c.Counter(self.bigrams)\n",
    "    \n",
    "    def p_unigram(self, w):\n",
    "        \"\"\"Calculates the probability a unigram appears in the distribution\"\"\"\n",
    "        return self.unigram_dist[w] / self.total_unigram_count\n",
    "    \n",
    "    def p_bigram(self, wprev, w):\n",
    "        \"\"\"Calculates the probability a bigram appears in the distribution\"\"\"\n",
    "        return self.bigram_dist[(wprev, w)] / self.total_bigram_count\n",
    "    \n",
    "    def pointwise_mi(self, wprev, w, p_bigram_func=None):\n",
    "        \"\"\"Calculates the pointwise mutual information in a word pair\"\"\"\n",
    "        p_bigram_func = self.p_bigram if p_bigram_func is None else p_bigram_func\n",
    "        return np.log2(p_bigram_func(wprev, w) / self.p_unigram(wprev) / self.p_unigram(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_en = LanguageModel(words_en)\n",
    "lm_cz = LanguageModel(words_cz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(lm):\n",
    "    # Obtain all word pairs in the word list, disregarding pairs in which one or both words appear less than 10 times in the corpus  \n",
    "    pairs = [pair for pair in lm.bigram_set\n",
    "             if lm.unigram_dist[pair[0]] >= lm.min_words \n",
    "             and lm.unigram_dist[pair[1]] >= lm.min_words]\n",
    "\n",
    "    mi = [(' '.join(pair), lm.pointwise_mi(*pair)) for pair in pairs]\n",
    "    return pd.DataFrame(mi, columns=['pair', 'mutual_information'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_en = mutual_information(lm_en).sort_values(by='mutual_information', ascending=False)\n",
    "mi_cz = mutual_information(lm_cz).sort_values(by='mutual_information', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>mutual_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43243</th>\n",
       "      <td>La Plata</td>\n",
       "      <td>14.169370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25638</th>\n",
       "      <td>Asa Gray</td>\n",
       "      <td>14.031867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Fritz Muller</td>\n",
       "      <td>13.362016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42970</th>\n",
       "      <td>worth while</td>\n",
       "      <td>13.332869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21972</th>\n",
       "      <td>faced tumbler</td>\n",
       "      <td>13.262480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11360</th>\n",
       "      <td>lowly organised</td>\n",
       "      <td>13.216899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23409</th>\n",
       "      <td>Malay Archipelago</td>\n",
       "      <td>13.110477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13752</th>\n",
       "      <td>shoulder stripe</td>\n",
       "      <td>13.053893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8643</th>\n",
       "      <td>Great Britain</td>\n",
       "      <td>12.914557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>United States</td>\n",
       "      <td>12.847442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>English carrier</td>\n",
       "      <td>12.525514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32285</th>\n",
       "      <td>specially endowed</td>\n",
       "      <td>12.401817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14364</th>\n",
       "      <td>branched off</td>\n",
       "      <td>12.377364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>Sir J</td>\n",
       "      <td>12.377364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12714</th>\n",
       "      <td>de Candolle</td>\n",
       "      <td>12.362016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39514</th>\n",
       "      <td>mental qualities</td>\n",
       "      <td>12.362016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6556</th>\n",
       "      <td>Galapagos Archipelago</td>\n",
       "      <td>12.344942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40173</th>\n",
       "      <td>red clover</td>\n",
       "      <td>12.323880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12549</th>\n",
       "      <td>self fertilisation</td>\n",
       "      <td>12.316928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>systematic affinity</td>\n",
       "      <td>12.251833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pair  mutual_information\n",
       "43243               La Plata           14.169370\n",
       "25638               Asa Gray           14.031867\n",
       "300             Fritz Muller           13.362016\n",
       "42970            worth while           13.332869\n",
       "21972          faced tumbler           13.262480\n",
       "11360        lowly organised           13.216899\n",
       "23409      Malay Archipelago           13.110477\n",
       "13752        shoulder stripe           13.053893\n",
       "8643           Great Britain           12.914557\n",
       "15550          United States           12.847442\n",
       "31660        English carrier           12.525514\n",
       "32285      specially endowed           12.401817\n",
       "14364           branched off           12.377364\n",
       "1803                   Sir J           12.377364\n",
       "12714            de Candolle           12.362016\n",
       "39514       mental qualities           12.362016\n",
       "6556   Galapagos Archipelago           12.344942\n",
       "40173             red clover           12.323880\n",
       "12549     self fertilisation           12.316928\n",
       "19331    systematic affinity           12.251833"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_en[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>mutual_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>Hamburger SV</td>\n",
       "      <td>14.288950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>14.062442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6347</th>\n",
       "      <td>Johna Newcomba</td>\n",
       "      <td>13.762882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28960</th>\n",
       "      <td>Č. Budějovice</td>\n",
       "      <td>13.633599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19030</th>\n",
       "      <td>série ATP</td>\n",
       "      <td>13.468968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17861</th>\n",
       "      <td>turnajové série</td>\n",
       "      <td>13.434411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>Tomáš Ježek</td>\n",
       "      <td>13.428981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17581</th>\n",
       "      <td>Lidové noviny</td>\n",
       "      <td>13.329922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>Lidových novin</td>\n",
       "      <td>13.271028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23072</th>\n",
       "      <td>veřejného mínění</td>\n",
       "      <td>13.062442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32507</th>\n",
       "      <td>teplota minus</td>\n",
       "      <td>12.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>jaderné zbraně</td>\n",
       "      <td>12.955527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35400</th>\n",
       "      <td>Ján Čarnogurský</td>\n",
       "      <td>12.955527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>Milan Máčala</td>\n",
       "      <td>12.897811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>lidských práv</td>\n",
       "      <td>12.862877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>společném státě</td>\n",
       "      <td>12.708434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>akciových společností</td>\n",
       "      <td>12.692492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18514</th>\n",
       "      <td>Pohár UEFA</td>\n",
       "      <td>12.625378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>privatizačních projektů</td>\n",
       "      <td>12.615677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>George Bushe</td>\n",
       "      <td>12.603010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pair  mutual_information\n",
       "6412              Hamburger SV           14.288950\n",
       "2686               Los Angeles           14.062442\n",
       "6347            Johna Newcomba           13.762882\n",
       "28960            Č. Budějovice           13.633599\n",
       "19030                série ATP           13.468968\n",
       "17861          turnajové série           13.434411\n",
       "8878               Tomáš Ježek           13.428981\n",
       "17581            Lidové noviny           13.329922\n",
       "35002           Lidových novin           13.271028\n",
       "23072         veřejného mínění           13.062442\n",
       "32507            teplota minus           12.981522\n",
       "16920           jaderné zbraně           12.955527\n",
       "35400          Ján Čarnogurský           12.955527\n",
       "6922              Milan Máčala           12.897811\n",
       "4130             lidských práv           12.862877\n",
       "6375           společném státě           12.708434\n",
       "14       akciových společností           12.692492\n",
       "18514               Pohár UEFA           12.625378\n",
       "6294   privatizačních projektů           12.615677\n",
       "14710             George Bushe           12.603010"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_cz[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>mutual_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28149</th>\n",
       "      <td>the ,</td>\n",
       "      <td>-8.790285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>. the</td>\n",
       "      <td>-8.407455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33255</th>\n",
       "      <td>. of</td>\n",
       "      <td>-7.901950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>of .</td>\n",
       "      <td>-7.901950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pair  mutual_information\n",
       "28149  the ,           -8.790285\n",
       "11222  . the           -8.407455\n",
       "33255   . of           -7.901950\n",
       "140     of .           -7.901950"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_en[:-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_dist(lm):\n",
    "    def mi_step(distance):\n",
    "        # Get all pairs in the word list a certain distance apart\n",
    "        pair_list = list(zip(lm.unigrams, lm.unigrams[distance+1:]))\n",
    "        dist = c.Counter(pair_list)\n",
    "    \n",
    "        # Obtain all word pairs in the word list, disregarding pairs in which one or both words appear less than 10 times in the corpus  \n",
    "        pairs = [pair for pair in list(set(pair_list))\n",
    "                 if lm.unigram_dist[pair[0]] >= lm.min_words \n",
    "                 and lm.unigram_dist[pair[1]] >= lm.min_words]\n",
    "        \n",
    "        p_bigram = lambda wprev, w: dist[(wprev, w)] / lm.total_bigram_count\n",
    "        \n",
    "        yield ((distance, wprev, w, lm.pointwise_mi(wprev, w, p_bigram)) for wprev,w in pairs)\n",
    "    \n",
    "    max_distance = 50\n",
    "    results = [m for distance in tqdm(range(1, max_distance+1)) for mi in mi_step(distance) for m in mi]\n",
    "        \n",
    "    return pd.DataFrame(results, columns=['distance', 'word0', 'word1', 'mutual_information'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:24<00:00,  2.01it/s]\n",
      "100%|██████████| 50/50 [00:24<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "mi_dist_en = mutual_information_dist(lm_en).sort_values(by='mutual_information', ascending=False)\n",
    "mi_dist_cz = mutual_information_dist(lm_cz).sort_values(by='mutual_information', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>word0</th>\n",
       "      <th>word1</th>\n",
       "      <th>mutual_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117857</th>\n",
       "      <td>2</td>\n",
       "      <td>survival</td>\n",
       "      <td>fittest</td>\n",
       "      <td>13.754333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42284</th>\n",
       "      <td>1</td>\n",
       "      <td>dimorphic</td>\n",
       "      <td>trimorphic</td>\n",
       "      <td>13.353454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127242</th>\n",
       "      <td>2</td>\n",
       "      <td>Alph</td>\n",
       "      <td>Candolle</td>\n",
       "      <td>13.236485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152017</th>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>Watson</td>\n",
       "      <td>13.169370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>1</td>\n",
       "      <td>Alph</td>\n",
       "      <td>de</td>\n",
       "      <td>13.053893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125929</th>\n",
       "      <td>2</td>\n",
       "      <td>Old</td>\n",
       "      <td>Worlds</td>\n",
       "      <td>13.053893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46878</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>12.946978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93923</th>\n",
       "      <td>2</td>\n",
       "      <td>unimportant</td>\n",
       "      <td>welfare</td>\n",
       "      <td>12.879864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181294</th>\n",
       "      <td>3</td>\n",
       "      <td>carrier</td>\n",
       "      <td>faced</td>\n",
       "      <td>12.695439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32030</th>\n",
       "      <td>1</td>\n",
       "      <td>rarer</td>\n",
       "      <td>rarer</td>\n",
       "      <td>12.525514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46327</th>\n",
       "      <td>1</td>\n",
       "      <td>plates</td>\n",
       "      <td>baleen</td>\n",
       "      <td>12.468931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61042</th>\n",
       "      <td>1</td>\n",
       "      <td>eastern</td>\n",
       "      <td>western</td>\n",
       "      <td>12.468931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56504</th>\n",
       "      <td>1</td>\n",
       "      <td>plains</td>\n",
       "      <td>La</td>\n",
       "      <td>12.432405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1</td>\n",
       "      <td>supplant</td>\n",
       "      <td>exterminate</td>\n",
       "      <td>12.368902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48055</th>\n",
       "      <td>1</td>\n",
       "      <td>oscillations</td>\n",
       "      <td>level</td>\n",
       "      <td>12.362016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21557</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>sanguinea</td>\n",
       "      <td>12.303872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1</td>\n",
       "      <td>analogical</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>12.246538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439355</th>\n",
       "      <td>6</td>\n",
       "      <td>incidental</td>\n",
       "      <td>systems</td>\n",
       "      <td>12.205896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63142</th>\n",
       "      <td>1</td>\n",
       "      <td>beasts</td>\n",
       "      <td>prey</td>\n",
       "      <td>12.179424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144102</th>\n",
       "      <td>2</td>\n",
       "      <td>plains</td>\n",
       "      <td>Plata</td>\n",
       "      <td>12.169370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance         word0        word1  mutual_information\n",
       "117857         2      survival      fittest           13.754333\n",
       "42284          1     dimorphic   trimorphic           13.353454\n",
       "127242         2          Alph     Candolle           13.236485\n",
       "152017         3             H       Watson           13.169370\n",
       "4742           1          Alph           de           13.053893\n",
       "125929         2           Old       Worlds           13.053893\n",
       "46878          1             E       Forbes           12.946978\n",
       "93923          2   unimportant      welfare           12.879864\n",
       "181294         3       carrier        faced           12.695439\n",
       "32030          1         rarer        rarer           12.525514\n",
       "46327          1        plates       baleen           12.468931\n",
       "61042          1       eastern      western           12.468931\n",
       "56504          1        plains           La           12.432405\n",
       "20850          1      supplant  exterminate           12.368902\n",
       "48055          1  oscillations        level           12.362016\n",
       "21557          1             F    sanguinea           12.303872\n",
       "1101           1    analogical     adaptive           12.246538\n",
       "439355         6    incidental      systems           12.205896\n",
       "63142          1        beasts         prey           12.179424\n",
       "144102         2        plains        Plata           12.169370"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_dist_en[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>word0</th>\n",
       "      <th>word1</th>\n",
       "      <th>mutual_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42390</th>\n",
       "      <td>1</td>\n",
       "      <td>ODÚ</td>\n",
       "      <td>VPN</td>\n",
       "      <td>14.119025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1</td>\n",
       "      <td>turnajové</td>\n",
       "      <td>ATP</td>\n",
       "      <td>13.614983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34912</th>\n",
       "      <td>1</td>\n",
       "      <td>Mistrovství</td>\n",
       "      <td>turnajové</td>\n",
       "      <td>13.410365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420187</th>\n",
       "      <td>8</td>\n",
       "      <td>výher</td>\n",
       "      <td>výher</td>\n",
       "      <td>13.318097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47620</th>\n",
       "      <td>1</td>\n",
       "      <td>Čechy</td>\n",
       "      <td>Slováky</td>\n",
       "      <td>13.303450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125482</th>\n",
       "      <td>3</td>\n",
       "      <td>Mistrovství</td>\n",
       "      <td>ATP</td>\n",
       "      <td>13.203914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996021</th>\n",
       "      <td>19</td>\n",
       "      <td>prohraná</td>\n",
       "      <td>dvojchyby</td>\n",
       "      <td>13.172205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83549</th>\n",
       "      <td>2</td>\n",
       "      <td>soužití</td>\n",
       "      <td>Slováků</td>\n",
       "      <td>13.062442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671230</th>\n",
       "      <td>13</td>\n",
       "      <td>prohraná</td>\n",
       "      <td>esa</td>\n",
       "      <td>13.051911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410727</th>\n",
       "      <td>8</td>\n",
       "      <td>III</td>\n",
       "      <td>IV</td>\n",
       "      <td>13.025916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82369</th>\n",
       "      <td>2</td>\n",
       "      <td>Mistrovství</td>\n",
       "      <td>série</td>\n",
       "      <td>13.023342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258799</th>\n",
       "      <td>5</td>\n",
       "      <td>esa</td>\n",
       "      <td>dvojchyby</td>\n",
       "      <td>12.987781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360927</th>\n",
       "      <td>25</td>\n",
       "      <td>Nastaseho</td>\n",
       "      <td>Newcomba</td>\n",
       "      <td>12.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099519</th>\n",
       "      <td>39</td>\n",
       "      <td>Bělehrad</td>\n",
       "      <td>Benfica</td>\n",
       "      <td>12.981522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>1</td>\n",
       "      <td>uchazečů</td>\n",
       "      <td>zaměstnání</td>\n",
       "      <td>12.955527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273270</th>\n",
       "      <td>6</td>\n",
       "      <td>prohraná</td>\n",
       "      <td>čisté</td>\n",
       "      <td>12.955527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38985</th>\n",
       "      <td>1</td>\n",
       "      <td>Sdružení</td>\n",
       "      <td>podnikatelů</td>\n",
       "      <td>12.855991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642996</th>\n",
       "      <td>12</td>\n",
       "      <td>čisté</td>\n",
       "      <td>dvojchyby</td>\n",
       "      <td>12.824282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179321</th>\n",
       "      <td>4</td>\n",
       "      <td>pražském</td>\n",
       "      <td>teplota</td>\n",
       "      <td>12.740514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279345</th>\n",
       "      <td>6</td>\n",
       "      <td>čisté</td>\n",
       "      <td>esa</td>\n",
       "      <td>12.703988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         distance        word0        word1  mutual_information\n",
       "42390           1          ODÚ          VPN           14.119025\n",
       "1122            1    turnajové          ATP           13.614983\n",
       "34912           1  Mistrovství    turnajové           13.410365\n",
       "420187          8        výher        výher           13.318097\n",
       "47620           1        Čechy      Slováky           13.303450\n",
       "125482          3  Mistrovství          ATP           13.203914\n",
       "996021         19     prohraná    dvojchyby           13.172205\n",
       "83549           2      soužití      Slováků           13.062442\n",
       "671230         13     prohraná          esa           13.051911\n",
       "410727          8          III           IV           13.025916\n",
       "82369           2  Mistrovství        série           13.023342\n",
       "258799          5          esa    dvojchyby           12.987781\n",
       "1360927        25    Nastaseho     Newcomba           12.981522\n",
       "2099519        39     Bělehrad      Benfica           12.981522\n",
       "13294           1     uchazečů   zaměstnání           12.955527\n",
       "273270          6     prohraná        čisté           12.955527\n",
       "38985           1     Sdružení  podnikatelů           12.855991\n",
       "642996         12        čisté    dvojchyby           12.824282\n",
       "179321          4     pražském      teplota           12.740514\n",
       "279345          6        čisté          esa           12.703988"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_dist_cz[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Best Friends\n",
    "\n",
    "#### Word Classes\n",
    "\n",
    "> **The Data**\n",
    "\n",
    "> Get `TEXTEN1.ptg`, `TEXTCZ1.ptg`. These are your data. They are almost the same as the .txt data you have used so far, except they now contain the part of speech tags in the following form:\n",
    "\n",
    "> `rady/NNFS2-----A----`  \n",
    "`,/Z:-------------`\n",
    "\n",
    "> where the tag is separated from the word by a slash ('/'). Be careful: the tags might contain everything (including slashes, dollar signs and other weird characters). It is guaranteed however that there is no slash-word.\n",
    "\n",
    "> Similarly for the English texts (except the tags are shorter of course).\n",
    "\n",
    "> **The Task**\n",
    "\n",
    "> Compute a full class hierarchy of **words** using the first 8,000 words of those data, and only for words occurring 10 times or more (use the same setting for both languages). Ignore the other words for building the classes, but keep them in the data for the bigram counts. For details on the algorithm, use the Brown et al. paper distributed in the class; some formulas are wrong, however, so please see the corrections on the web (Class 12, formulas for Trick \\#4). Note the history of the merges, and attach it to your homework. Now run the same algorithm again, but stop when reaching 15 classes. Print out all the members of your 15 classes and attach them too.\n",
    "\n",
    "> **Hints:**\n",
    "\n",
    "> The initial mutual information is (English, words, limit 8000):\n",
    "\n",
    "> `4.99726326162518` (if you add one extra word at the beginning of the data)  \n",
    "> `4.99633675507535` (if you use the data as they are and are carefull at the beginning and end).\n",
    "\n",
    "> NB: the above numbers are finally confirmed from an independent source :-).\n",
    "\n",
    "> The first 5 merges you get on the English data should be:\n",
    "\n",
    "> `case subject`  \n",
    "> `cannot may`  \n",
    "> `individuals structure`  \n",
    "> `It there`  \n",
    "> `even less`  \n",
    "\n",
    "> The loss of Mutual Information when merging the words \"case\" and \"subject\":\n",
    "\n",
    "> Minimal loss: `0.00219656653357569` for `case+subject`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class LmCluster:\n",
    "    def __init__(self, words):\n",
    "        self.lm = LanguageModel(words)\n",
    "        \n",
    "#         self.vocab2word = lm.unigram_set\n",
    "#         self.word2vocab = {word:i for i,word in enumerate(vocab2word)}\n",
    "#         self.vocab2class = list(range(len(self.vocab2word))) # Start with each word in its own class\n",
    "        self.class2vocab = lm.unigram_set\n",
    "        self.vocab2class = {word:i for i,word in enumerate(self.class2vocab)} # Start with each word in its own class\n",
    "        \n",
    "        self.text_v = lm.unigrams\n",
    "#         self.text_c = [self.vocab2class[word] for word in self.text_v]\n",
    "        \n",
    "#         class_dist = c.Counter(self.text_c)\n",
    "#         class_pair_dist = c.Counter(zip(self.text_c, self.text_c[1:]))\n",
    "        \n",
    "        c1, c2 = self.find_best_merge(vocab2class)\n",
    "        print(self.vocab2word[c1], self.vocab2word[c2])\n",
    "    \n",
    "    def find_best_merge(self, vocab2class):\n",
    "        text_c = [self.vocab2class[word] for word in self.text_v]\n",
    "        classes = list(set(text_c))\n",
    "        merges = (mi(vocab2class, c1, c2), c1, c2 for c1, c2 in itertools.combinations(classes, 2))\n",
    "        best_merge = min(merges, key=lambda x: x[0])\n",
    "        \n",
    "    def mi(self, vocab2class, c1, c2):\n",
    "        \n",
    "        \n",
    "        return np.sum([lm.p_bigram(*pair) * lm.pointwise_mi(*pair) for pair in self.word_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-0985066f91a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLmCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_en\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-0183bea024ae>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab2class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_best_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "cluster = LmCluster(words_en[:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster.word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.996416777233102"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutual_information_total(lm):\n",
    "    pairs = lm.bigram_set\n",
    "    return np.sum([lm.p_bigram(*pair) * lm.pointwise_mi(*pair) for pair in pairs])\n",
    "\n",
    "mutual_information_total(LanguageModel(words_en[:8000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0008464843920785725, 8.002215775171351e-05)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutual_information_total(words):\n",
    "    def p_unigram(w):\n",
    "        \"\"\"Calculates the probability a unigram appears in the distribution\"\"\"\n",
    "        return unigram_dist[w] / total_unigram_count\n",
    "    \n",
    "    def p_bigram(wprev, w):\n",
    "        \"\"\"Calculates the probability a bigram appears in the distribution\"\"\"\n",
    "        return bigram_dist[(wprev, w)] / total_bigram_count\n",
    "    \n",
    "    def pointwise_mi(wprev, w):\n",
    "        \"\"\"Calculates the pointwise mutual information in a word pair\"\"\"\n",
    "        return np.log2(p_bigram(wprev, w) / p_unigram(wprev) / p_unigram(w))\n",
    "    \n",
    "    # Unigrams\n",
    "    unigrams = words\n",
    "    unigram_set = list(set(unigrams))\n",
    "    total_unigram_count = len(unigrams)\n",
    "    unigram_dist = c.Counter(unigrams)\n",
    "\n",
    "    # Bigrams\n",
    "    bigrams = list(zip(words, words[1:]))\n",
    "    bigram_set = list(set(bigrams))\n",
    "    total_bigram_count = len(bigrams)\n",
    "    bigram_dist = c.Counter(bigrams)\n",
    "    \n",
    "    return np.sum([p_bigram(*pair) * pointwise_mi(*pair) for pair in bigram_set])\n",
    "    \n",
    "t = mutual_information_total(list(words_en[:8000]))\n",
    "# t = mutual_information_total(list(words_en[:8000]))\n",
    "t - 4.99726326162518, t - 4.99633675507535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.99726326162518 (if you add one extra word at the beginning of the data)\n",
    "4.99633675507535 (if you use the data as they are and are carefull at the beginning and end).\n",
    "\n",
    "8.002215775171351e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tag Classes\n",
    "\n",
    "> Use the same original data as above, but this time, you will compute the classes for tags (the strings after slashes). Compute tag classes for all tags appearing 5 times or more in the data. Use as much data as time allows. You will be graded relative to the other student's results. Again, note the full history of merges, and attach it to your homework. Pick three interesting classes as the algorithm goes (English data only; Czech optional), and comment on them (why you think you see those tags there together (or not), etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
